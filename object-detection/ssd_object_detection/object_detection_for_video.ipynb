{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD Object Detection Demo\n",
    "\n",
    "This notebook will walk you step by step through the process of using a pre-trained model to detect objects in a video. \n",
    "* You may first go over the `object_detection_tutorial` notebook in the same folder as this notebook is residing in.\n",
    "* The code in this notebook is from [lazyprogrammer SSD](https://github.com/lazyprogrammer/machine_learning_examples/blob/master/cnn_class2/ssd.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "    raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change this to wherever you cloned the tensorflow models repo\n",
    "# # which I assume you've already downloaded from:\n",
    "# # https://github.com/tensorflow/models\n",
    "# RESEARCH_PATH = '../../tf-models/research'\n",
    "# MODELS_PATH = '../../tf-models/research/object_detection'\n",
    "# sys.path.append(RESEARCH_PATH)\n",
    "# sys.path.append(MODELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory.\n",
    "* Assume that you have already downloaded the model\n",
    "* check `object_detection_tutorial` notebook for detail of downloading the SSD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames processed: 50, Speed: 4.820915522711623 fps\n"
     ]
    }
   ],
   "source": [
    "# do some object detection\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        \n",
    "        # Definite input and output Tensors for detection_graph\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        \n",
    "        # Each box represents a part of the image where a particular object was detected.\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        \n",
    "        # Each score represent how level of confidence for each of the objects.\n",
    "        # Score is shown on the result image, together with the class label.\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        # instead of looping through test images, we'll now loop\n",
    "        # through our video!\n",
    "\n",
    "        # get the videos from:\n",
    "        # https://lazyprogrammer.me/cnn_class2_videos.zip\n",
    "        # and put them into the same folder as this file\n",
    "\n",
    "        # open the video\n",
    "        \n",
    "        input_video = 'catdog'\n",
    "#         input_video = 'safari'\n",
    "#         input_video = 'traffic'\n",
    "\n",
    "        # read video from videos folder\n",
    "        video_reader = imageio.get_reader('videos/%s.mp4' % input_video)\n",
    "    \n",
    "        # put annotated video to videos_out folder\n",
    "        video_writer = imageio.get_writer('videos_out/%s_annotated.mp4' % input_video, fps=10)\n",
    "\n",
    "        # loop through and process each frame\n",
    "        t0 = datetime.now()\n",
    "        n_frames = 0\n",
    "        for frame in video_reader:\n",
    "            # rename for convenience\n",
    "            image_np = frame\n",
    "            n_frames += 1\n",
    "\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num) = sess.run(\n",
    "              [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "              feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np,\n",
    "              np.squeeze(boxes),\n",
    "              np.squeeze(classes).astype(np.int32),\n",
    "              np.squeeze(scores),\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=8)\n",
    "      \n",
    "            # instead of plotting image, we write the frame to video\n",
    "            video_writer.append_data(image_np)\n",
    "\n",
    "        fps = n_frames / (datetime.now() - t0).total_seconds()\n",
    "        print(\"Frames processed: %s, Speed: %s fps\" % (n_frames, fps))\n",
    "\n",
    "        # clean up\n",
    "        video_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Have fun\n",
    "\n",
    "* You can use your own webcam and see how SSD can be used to annotate you and objects in your environment\n",
    "* You need to install openCV which is somewhat non-trivial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:computer_vision]",
   "language": "python",
   "name": "conda-env-computer_vision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
